{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3e101f",
   "metadata": {},
   "source": [
    "# Chest X-Ray Image Generation using GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyhealth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303f1068",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b89c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/PyHealth/pyhealth/trainer.py:12: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n",
      "/home/ubuntu/PyHealth/pyhealth/sampler/sage_sampler.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.datasets import split_by_visit, get_dataloader\n",
    "from pyhealth.trainer import Trainer\n",
    "from pyhealth.datasets import COVID19CXRDataset\n",
    "from pyhealth.models import VAE\n",
    "from pyhealth.processors import ImageProcessor\n",
    "from torchvision import transforms\n",
    "from pyhealth.processors import SequenceProcessor\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53feb87e",
   "metadata": {},
   "source": [
    "## STEP 1: load the chest Xray data\n",
    "\n",
    "We also prepare the data:\n",
    "- resize images to 128x128\n",
    "- split train/test/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download command (uncomment to run)\n",
    "# !curl -L -o ~/Downloads/covid19-radiography-database.zip https://www.kaggle.com/api/v1/datasets/download/tawsifurrahman/covid19-radiography-database\n",
    "# !unzip ~/Downloads/covid19-radiography-database.zip -d ~/Downloads/COVID-19_Radiography_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13913032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No config path provided, using default config\n",
      "Initializing covid19_cxr dataset from /home/ubuntu/Downloads/COVID-19_Radiography_Dataset (dev mode: False)\n",
      "Scanning table: covid19_cxr from /home/ubuntu/Downloads/COVID-19_Radiography_Dataset/covid19_cxr-metadata-pyhealth.csv\n",
      "Collecting global event dataframe...\n",
      "Collected dataframe with shape: (21165, 6)\n",
      "Dataset: covid19_cxr\n",
      "Dev mode: False\n",
      "Number of patients: 21165\n",
      "Number of events: 21165\n",
      "Setting task COVID19CXRClassification for covid19_cxr base dataset...\n",
      "Generating samples with 1 worker(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples for COVID19CXRClassification with 1 worker: 100%|██████████| 21165/21165 [00:08<00:00, 2637.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label disease vocab: {'COVID': 0, 'Lung Opacity': 1, 'Normal': 2, 'Viral Pneumonia': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing samples: 100%|██████████| 21165/21165 [01:18<00:00, 270.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 21165 samples for task COVID19CXRClassification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_size = 128\n",
    "covid19cxr_path = \"~/Downloads/COVID-19_Radiography_Dataset\"\n",
    "\n",
    "base_dataset = COVID19CXRDataset(covid19cxr_path)\n",
    "\n",
    "base_dataset.stats()\n",
    "\n",
    "\n",
    "# Step 2: Set task with custom image processing for GAN\n",
    "image_processor = ImageProcessor(image_size=image_size, mode=\"RGB\")  # Resize to 128x128 for GAN\n",
    "\n",
    "sample_dataset = base_dataset.set_task(input_processors={\"image\": image_processor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n",
      "loader size: train/val/test 16932 2116 2117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split dataset\n",
    "train_dataset, val_dataset, test_dataset = split_by_visit(\n",
    "    sample_dataset, [0.8, 0.1, 0.1]\n",
    ")\n",
    "\n",
    "train_dataloader = get_dataloader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_dataloader = get_dataloader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_dataloader = get_dataloader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "data = next(iter(train_dataloader))\n",
    "\n",
    "print(data[\"image\"][0].shape)\n",
    "\n",
    "print(\n",
    "    \"loader size: train/val/test\",\n",
    "    len(train_dataset),\n",
    "    len(val_dataset),\n",
    "    len(test_dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3",
   "metadata": {},
   "source": [
    "### STEP3: define the GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gan_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.models import GAN\n",
    "\n",
    "model = GAN(\n",
    "    input_channel=3,\n",
    "    input_size=128,\n",
    "    hidden_dim=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4",
   "metadata": {},
   "source": [
    "### STEP4: training the GAN model in an adversarial way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Loss function\n",
    "loss = torch.nn.BCELoss()\n",
    "\n",
    "opt_G = torch.optim.AdamW(model.generator.parameters(), lr=1e-3)\n",
    "opt_D = torch.optim.AdamW(model.discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "curve_D, curve_G = [], []\n",
    "\n",
    "for epoch in range(50):\n",
    "    curve_G.append(0)\n",
    "    curve_D.append(0)\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        \n",
    "        \"\"\" train discriminator \"\"\"\n",
    "        \n",
    "        opt_D.zero_grad()\n",
    "        \n",
    "        real_imgs = batch[\"image\"].to(device)\n",
    "        \n",
    "        batch_size = real_imgs.shape[0]\n",
    "        \n",
    "        fake_imgs = model.generate_fake(batch_size, device)\n",
    "        \n",
    "        real_loss = loss(model.discriminator(real_imgs), torch.ones(batch_size, 1).to(device))\n",
    "        fake_loss = loss(model.discriminator(fake_imgs.detach()), torch.zeros(batch_size, 1).to(device))\n",
    "        loss_D = (real_loss + fake_loss) / 2\n",
    "        \n",
    "        loss_D.backward()\n",
    "        opt_D.step()\n",
    "        \n",
    "        \"\"\" train generator \"\"\"\n",
    "        \n",
    "        opt_G.zero_grad()\n",
    "        loss_G = loss(model.discriminator(fake_imgs), torch.ones(batch_size, 1).to(device))\n",
    "        \n",
    "        loss_G.backward()\n",
    "        opt_G.step()\n",
    "        \n",
    "        curve_G[-1] += loss_G.item()\n",
    "        curve_D[-1] += loss_D.item()\n",
    "        \n",
    "    print(f\"epoch: {epoch} --- loss of G: {curve_G[-1]}, loss of D: {curve_D[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exp2",
   "metadata": {},
   "source": [
    "### EXP 2: synthesize random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    fake_imgs = model.generate_fake(1, device).detach().cpu()\n",
    "    plt.imshow(fake_imgs[0].permute(1, 2, 0).clamp(0, 1))  # RGB image\n",
    "    plt.title(\"Generated Chest X-Ray\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
