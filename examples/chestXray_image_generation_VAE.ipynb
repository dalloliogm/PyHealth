{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chest X-Ray Image Generation using VAE\n",
    "\n",
    "This notebook illustrates how to use the VAE module to generate X-Ray images, including the new features for conditional generation and time-series support.\n",
    "\n",
    "We will take the COVID-19 CXR dataset as starting point. This dataset is freely available on Kaggle and contains images of Chest X-Rays from COVID-19 patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data\n",
    "\n",
    "Data is available from Kaggle. If it is not already available locally, download it with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download command (uncomment to run)\n",
    "# !curl -L -o ~/Downloads/covid19-radiography-database.zip https://www.kaggle.com/api/v1/datasets/download/tawsifurrahman/covid19-radiography-database\n",
    "# !unzip ~/Downloads/covid19-radiography-database.zip -d ~/Downloads/COVID-19_Radiography_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data with PyHealth Datasets\n",
    "\n",
    "Use the COVID19CXRDataset to load this data. For custom datasets, see the `BaseImageDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import split_by_visit, get_dataloader\n",
    "from pyhealth.trainer import Trainer\n",
    "from pyhealth.datasets import COVID19CXRDataset\n",
    "from pyhealth.models import VAE\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load data\n",
    "root = \"/home/ubuntu/Downloads/COVID-19_Radiography_Dataset\"\n",
    "base_dataset = COVID19CXRDataset(root)\n",
    "\n",
    "# Step 2: Set task\n",
    "sample_dataset = base_dataset.set_task()\n",
    "\n",
    "# Transformations to normalize pixel intensity into [0, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x if x.shape[0] == 3 else x.repeat(3, 1, 1)),  # Use first channel if needed\n",
    "    transforms.Resize((128, 128)),\n",
    "])\n",
    "\n",
    "def encode(sample):\n",
    "    sample[\"path\"] = transform(sample[\"path\"])\n",
    "    return sample\n",
    "\n",
    "sample_dataset.set_transform(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_dataset, val_dataset, test_dataset = split_by_visit(\n",
    "    sample_dataset, [0.6, 0.2, 0.2]\n",
    ")\n",
    "train_dataloader = get_dataloader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_dataloader = get_dataloader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_dataloader = get_dataloader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# Check data\n",
    "data = next(iter(train_dataloader))\n",
    "print(\"Data keys:\", data.keys())\n",
    "print(\"Image shape:\", data[\"path\"][0].shape)\n",
    "print(f\"Dataset sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic VAE Training (Image Generation)\n",
    "\n",
    "Train a standard VAE for unconditional image generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = VAE(\n",
    "    dataset=sample_dataset,\n",
    "    feature_keys=[\"path\"],\n",
    "    label_key=\"path\",\n",
    "    mode=\"regression\",\n",
    "    input_type=\"image\",\n",
    "    input_channel=3,\n",
    "    input_size=128,\n",
    "    hidden_dim=128,\n",
    ")\n",
    "\n",
    "# Define trainer\n",
    "trainer = Trainer(model=model, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", \n",
    "                 metrics=[\"kl_divergence\", \"mse\", \"mae\"])\n",
    "\n",
    "# Train (reduce epochs for demo)\n",
    "trainer.train(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    epochs=5,  # Reduced for demo\n",
    "    monitor=\"kl_divergence\",\n",
    "    monitor_criterion=\"min\",\n",
    "    optimizer_params={\"lr\": 1e-3},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(\"Evaluation results:\")\n",
    "eval_results = trainer.evaluate(test_dataloader)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Real vs Reconstructed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get real and reconstructed images\n",
    "X, X_rec, _ = trainer.inference(test_dataloader)\n",
    "\n",
    "# Plot comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(X[0].reshape(128, 128, 3)[:, :, 0], cmap=\"gray\")\n",
    "ax1.set_title(\"Real Chest X-Ray\")\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(X_rec[0].reshape(128, 128, 3)[:, :, 0], cmap=\"gray\")\n",
    "ax2.set_title(\"Reconstructed by VAE\")\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"chestxray_vae_comparison.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Random Image Generation\n",
    "\n",
    "Generate new images by sampling from the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic images\n",
    "model = trainer.model\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Sample from latent space\n",
    "    z = torch.randn(1, 128).to(model.device)\n",
    "    \n",
    "    # Reshape for decoder (add spatial dims)\n",
    "    z = z.unsqueeze(2).unsqueeze(3)\n",
    "    \n",
    "    # Generate image\n",
    "    generated = model.decoder(z).detach().cpu().numpy()\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(generated[0].reshape(128, 128, 3)[:, :, 0], cmap=\"gray\")\n",
    "    plt.title(\"Generated Chest X-Ray\")\n",
    "    plt.axis('off')\n",
    "    plt.savefig(\"chestxray_vae_synthetic.png\", dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Feature: Conditional VAE\n",
    "\n",
    "Generate images conditioned on additional features (e.g., diagnosis codes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with conditional features\n",
    "samples_with_conditions = [\n",
    "    {\n",
    "        \"patient_id\": \"patient-0\",\n",
    "        \"visit_id\": \"visit-0\",\n",
    "        \"path\": torch.rand(3, 128, 128),  # Dummy image\n",
    "        \"conditions\": [\"COVID-19\", \"pneumonia\"],\n",
    "        \"label\": 0,\n",
    "    },\n",
    "    {\n",
    "        \"patient_id\": \"patient-1\",\n",
    "        \"visit_id\": \"visit-1\",\n",
    "        \"path\": torch.rand(3, 128, 128),\n",
    "        \"conditions\": [\"normal\"],\n",
    "        \"label\": 1,\n",
    "    },\n",
    "]\n",
    "\n",
    "from pyhealth.datasets import SampleDataset\n",
    "\n",
    "cond_dataset = SampleDataset(\n",
    "    samples=samples_with_conditions,\n",
    "    input_schema={\"path\": \"tensor\", \"conditions\": \"sequence\"},\n",
    "    output_schema={\"label\": \"binary\"},\n",
    "    dataset_name=\"conditional_demo\",\n",
    ")\n",
    "\n",
    "# Conditional VAE model\n",
    "cond_model = VAE(\n",
    "    dataset=cond_dataset,\n",
    "    feature_keys=[\"path\"],\n",
    "    label_key=\"label\",\n",
    "    mode=\"binary\",\n",
    "    input_type=\"image\",\n",
    "    input_channel=3,\n",
    "    input_size=128,\n",
    "    hidden_dim=64,\n",
    "    conditional_feature_keys=[\"conditions\"],  # New parameter\n",
    ")\n",
    "\n",
    "print(\"Conditional VAE created with embedding model for conditions\")\n",
    "print(f\"Has embedding model: {hasattr(cond_model, 'embedding_model')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Feature: Time-Series VAE\n",
    "\n",
    "Use VAE for time-series data reconstruction and generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-series dataset\n",
    "ts_samples = [\n",
    "    {\n",
    "        \"patient_id\": \"patient-0\",\n",
    "        \"visit_id\": \"visit-0\",\n",
    "        \"visits\": [\"diagnosis1\", \"diagnosis2\", \"procedure1\"],\n",
    "        \"label\": 1.0,\n",
    "    },\n",
    "    {\n",
    "        \"patient_id\": \"patient-1\",\n",
    "        \"visit_id\": \"visit-1\",\n",
    "        \"visits\": [\"diagnosis3\"],\n",
    "        \"label\": 0.5,\n",
    "    },\n",
    "]\n",
    "\n",
    "ts_dataset = SampleDataset(\n",
    "    samples=ts_samples,\n",
    "    input_schema={\"visits\": \"sequence\"},\n",
    "    output_schema={\"label\": \"regression\"},\n",
    "    dataset_name=\"timeseries_demo\",\n",
    ")\n",
    "\n",
    "# Time-series VAE model\n",
    "ts_model = VAE(\n",
    "    dataset=ts_dataset,\n",
    "    feature_keys=[\"visits\"],\n",
    "    label_key=\"label\",\n",
    "    mode=\"regression\",\n",
    "    input_type=\"timeseries\",  # New parameter\n",
    "    hidden_dim=64,\n",
    ")\n",
    "\n",
    "print(\"Time-series VAE created\")\n",
    "print(f\"Input type: {ts_model.input_type}\")\n",
    "print(f\"Has embedding model: {hasattr(ts_model, 'embedding_model')}\")\n",
    "print(f\"Has RNN encoder: {hasattr(ts_model, 'encoder_rnn')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The enhanced VAE now supports:\n",
    "- **Image generation**: Unconditional and conditional\n",
    "- **Time-series modeling**: For sequential medical data\n",
    "- **Flexible embeddings**: Integrated with PyHealth's EmbeddingModel\n",
    "\n",
    "Key new parameters:\n",
    "- `input_type`: 'image' or 'timeseries'\n",
    "- `conditional_feature_keys`: List of keys for conditional generation\n",
    "\n",
    "This enables more sophisticated generative models for medical data analysis and synthesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
