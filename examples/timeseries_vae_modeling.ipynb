{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Modeling with VAE\n",
    "\n",
    "This notebook demonstrates how to use the enhanced VAE model for time-series data analysis and generation. Unlike image VAEs that work with spatial patterns, time-series VAEs model sequential patterns in medical data.\n",
    "\n",
    "## Key Concepts:\n",
    "- **Sequence Encoding**: RNN-based encoder captures temporal dependencies\n",
    "- **Latent Representation**: Compressed representation of patient trajectories\n",
    "- **Sequence Generation**: RNN decoder reconstructs realistic medical sequences\n",
    "\n",
    "## Applications:\n",
    "- Patient trajectory modeling and generation\n",
    "- Medical sequence anomaly detection\n",
    "- Synthetic data generation for rare conditions\n",
    "- Treatment pattern analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import split_by_visit, get_dataloader\n",
    "from pyhealth.trainer import Trainer\n",
    "from pyhealth.models import VAE\n",
    "from pyhealth.datasets import SampleDataset\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Time-Series Medical Data\n",
    "\n",
    "We'll create sample patient trajectories showing disease progression and treatment sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample time-series medical data\n",
    "ts_samples = [\n",
    "    {\n",
    "        \"patient_id\": \"patient-0\",\n",
    "        \"visit_id\": \"visit-0\",\n",
    "        \"visits\": [\"diabetes\", \"metformin\", \"hba1c_test\", \"insulin\"],\n",
    "        \"label\": 1.0,\n",
    "    },\n",
    "    {\n",
    "        \"patient_id\": \"patient-1\",\n",
    "        \"visit_id\": \"visit-1\",\n",
    "        \"visits\": [\"hypertension\", \"lisinopril\", \"bp_check\", \"followup\"],\n",
    "        \"label\": 0.5,\n",
    "    },\n",
    "    {\n",
    "        \"patient_id\": \"patient-2\",\n",
    "        \"visit_id\": \"visit-2\",\n",
    "        \"visits\": [\"asthma\", \"albuterol\", \"peak_flow\", \"steroids\"],\n",
    "        \"label\": 0.8,\n",
    "    },\n",
    "    {\n",
    "        \"patient_id\": \"patient-3\",\n",
    "        \"visit_id\": \"visit-3\",\n",
    "        \"visits\": [\"depression\", \"sertraline\", \"therapy\", \"counseling\"],\n",
    "        \"label\": 0.3,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create dataset\n",
    "ts_dataset = SampleDataset(\n",
    "    samples=ts_samples,\n",
    "    input_schema={\"visits\": \"sequence\"},\n",
    "    output_schema={\"label\": \"regression\"},\n",
    "    dataset_name=\"timeseries_demo\",\n",
    ")\n",
    "\n",
    "print(\"Time-series dataset created\")\n",
    "print(f\"Number of samples: {len(ts_dataset)}\")\n",
    "print(f\"Vocabulary size: {len(ts_dataset.input_processors['visits'].code_vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train Time-Series VAE\n",
    "\n",
    "The VAE will learn to encode patient trajectories into a latent space and reconstruct them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-series VAE model\n",
    "ts_model = VAE(\n",
    "    dataset=ts_dataset,\n",
    "    feature_keys=[\"visits\"],\n",
    "    label_key=\"label\",\n",
    "    mode=\"regression\",\n",
    "    input_type=\"timeseries\",  # Key parameter for time-series mode\n",
    "    hidden_dim=32,  # Smaller latent dimension for sequences\n",
    ")\n",
    "\n",
    "print(\"Time-series VAE created\")\n",
    "print(f\"Input type: {ts_model.input_type}\")\n",
    "print(f\"Has embedding model: {hasattr(ts_model, 'embedding_model')}\")\n",
    "print(f\"Has RNN encoder: {hasattr(ts_model, 'encoder_rnn')}\")\n",
    "print(f\"Latent dimension: {ts_model.hidden_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Time-Series VAE Architecture\n",
    "\n",
    "The time-series VAE differs from image VAEs:\n",
    "\n",
    "1. **EmbeddingModel**: Converts categorical sequences to dense vectors\n",
    "2. **RNN Encoder**: Processes sequential embeddings, capturing temporal patterns\n",
    "3. **Latent Space**: Fixed-size representation of the entire sequence\n",
    "4. **Linear Decoder**: Reconstructs the sequence's compressed representation\n",
    "\n",
    "This architecture can learn patterns like \"diabetes → metformin → insulin\" or \"asthma → albuterol → steroids\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "train_dataloader = get_dataloader(ts_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=ts_model, \n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    metrics=[\"kl_divergence\", \"mse\", \"mae\"]\n",
    ")\n",
    "\n",
    "# Train the model (reduced epochs for demo)\n",
    "print(\"Training time-series VAE...\")\n",
    "trainer.train(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=train_dataloader,  # Using same data for demo\n",
    "    epochs=5,\n",
    "    monitor=\"kl_divergence\",\n",
    "    monitor_criterion=\"min\",\n",
    "    optimizer_params={\"lr\": 1e-3},\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Reconstruction Performance\n",
    "\n",
    "Check how well the VAE reconstructs the original sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on training data\n",
    "eval_results = trainer.evaluate(train_dataloader)\n",
    "print(\"Evaluation Results:\")\n",
    "for metric, value in eval_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Get reconstruction examples\n",
    "data_batch = next(iter(train_dataloader))\n",
    "with torch.no_grad():\n",
    "    output = ts_model(**data_batch)\n",
    "    \n",
    "print(f\"\\nReconstruction shape: {output['y_prob'].shape}\")\n",
    "print(f\"Original shape: {output['y_true'].shape}\")\n",
    "print(f\"Loss: {output['loss'].item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Medical Sequences\n",
    "\n",
    "Sample from the latent space to generate new patient trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new sequences by sampling from latent space\n",
    "ts_model.eval()\n",
    "with torch.no_grad():\n",
    "    # Sample random latent vectors\n",
    "    latent_samples = torch.randn(3, ts_model.hidden_dim).to(ts_model.device)\n",
    "    \n",
    "    # Decode to get sequence representations\n",
    "    generated_sequences = ts_model.decoder(latent_samples)\n",
    "    \n",
    "    print(\"Generated sequence representations:\")\n",
    "    print(f\"Shape: {generated_sequences.shape}\")\n",
    "    print(f\"Sample values: {generated_sequences[0, :5].cpu().numpy()}\")\n",
    "    \n",
    "    # The generated sequences represent points in the embedded space\n",
    "    # In a full implementation, you might use a decoder RNN to generate\n",
    "    # actual token sequences, but here we show the latent generation concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "### How Time-Series VAE Works:\n",
    "1. **Input Processing**: Categorical sequences are embedded using the EmbeddingModel\n",
    "2. **Sequence Encoding**: RNN processes the embedded sequence to capture temporal patterns\n",
    "3. **Latent Compression**: Variable-length sequences become fixed-size latent vectors\n",
    "4. **Reconstruction**: Decoder attempts to recreate the embedded sequence representation\n",
    "\n",
    "### Medical Applications:\n",
    "- **Trajectory Analysis**: Understand typical patient progression patterns\n",
    "- **Synthetic Data**: Generate realistic patient histories for research\n",
    "- **Anomaly Detection**: Identify unusual treatment sequences\n",
    "- **Outcome Prediction**: Learn sequence patterns that correlate with outcomes\n",
    "\n",
    "### Differences from Image VAE:\n",
    "- **Temporal vs Spatial**: Captures time-ordered dependencies instead of spatial patterns\n",
    "- **Variable Length**: Handles sequences of different lengths\n",
    "- **Categorical Data**: Works with medical codes, diagnoses, treatments\n",
    "- **Generation**: Creates new realistic patient trajectories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}