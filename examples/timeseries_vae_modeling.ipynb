{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Modeling with VAE\n",
    "\n",
    "This notebook demonstrates how to use the enhanced VAE model for time-series data analysis and generation. Unlike image VAEs that work with spatial patterns, time-series VAEs model sequential patterns in medical data.\n",
    "\n",
    "## Key Concepts:\n",
    "- **Sequence Encoding**: RNN-based encoder captures temporal dependencies\n",
    "- **Latent Representation**: Compressed representation of patient trajectories\n",
    "- **Sequence Generation**: RNN decoder reconstructs realistic medical sequences\n",
    "\n",
    "## Applications:\n",
    "- Patient trajectory modeling and generation\n",
    "- Medical sequence anomaly detection\n",
    "- Synthetic data generation for rare conditions\n",
    "- Treatment pattern analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/PyHealth/pyhealth/trainer.py:12: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n",
      "/home/ubuntu/PyHealth/pyhealth/sampler/sage_sampler.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.datasets import split_by_visit, get_dataloader\n",
    "from pyhealth.trainer import Trainer\n",
    "from pyhealth.models import VAE\n",
    "from pyhealth.datasets import MIMIC4Dataset\n",
    "from pyhealth.tasks import MortalityPredictionMIMIC4\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MIMIC4 Demo Dataset\n",
    "\n",
    "We'll use the MIMIC4 demo dataset to demonstrate time-series VAE on real medical sequences.\n",
    "\n",
    "**Setup Instructions:**\n",
    "1. Download MIMIC4 demo data from: https://physionet.org/files/mimic-iv-demo/2.2/\n",
    "2. Create a `data/mimic4_demo` directory in your project root\n",
    "3. Extract the downloaded files into `data/mimic4_demo/hosp/` subdirectory\n",
    "4. Update the `ehr_root` path below if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage Starting MIMIC4Dataset init: 812.4 MB\n",
      "Initializing MIMIC4EHRDataset with tables: ['diagnoses_icd', 'procedures_icd', 'prescriptions'] (dev mode: True)\n",
      "Using default EHR config: /home/ubuntu/PyHealth/pyhealth/datasets/configs/mimic4_ehr.yaml\n",
      "Memory usage Before initializing mimic4_ehr: 812.4 MB\n",
      "Initializing mimic4_ehr dataset from /home/ubuntu/PyHealth/data/mimic-iv-clinical-database-demo-2.2/ (dev mode: False)\n",
      "Scanning table: diagnoses_icd from /home/ubuntu/PyHealth/data/mimic-iv-clinical-database-demo-2.2/hosp/diagnoses_icd.csv.gz\n",
      "Joining with table: /home/ubuntu/PyHealth/data/mimic-iv-clinical-database-demo-2.2/hosp/admissions.csv.gz\n",
      "Scanning table: procedures_icd from /home/ubuntu/PyHealth/data/mimic-iv-clinical-database-demo-2.2/hosp/procedures_icd.csv.gz\n",
      "Joining with table: /home/ubuntu/PyHealth/data/mimic-iv-clinical-database-demo-2.2/hosp/admissions.csv.gz\n",
      "Scanning table: prescriptions from /home/ubuntu/PyHealth/data/mimic-iv-clinical-database-demo-2.2/hosp/prescriptions.csv.gz\n",
      "Scanning table: patients from /home/ubuntu/PyHealth/data/mimic-iv-clinical-database-demo-2.2/hosp/patients.csv.gz\n",
      "Scanning table: admissions from /home/ubuntu/PyHealth/data/mimic-iv-clinical-database-demo-2.2/hosp/admissions.csv.gz\n",
      "Scanning table: icustays from /home/ubuntu/PyHealth/data/mimic-iv-clinical-database-demo-2.2/icu/icustays.csv.gz\n",
      "Memory usage After initializing mimic4_ehr: 815.3 MB\n",
      "Memory usage After EHR dataset initialization: 815.3 MB\n",
      "Memory usage Before combining data: 815.3 MB\n",
      "Combining data from ehr dataset\n",
      "Creating combined dataframe\n",
      "Memory usage After combining data: 815.3 MB\n",
      "Memory usage Completed MIMIC4Dataset init: 815.3 MB\n",
      "Setting task MortalityPredictionMIMIC4 for mimic4 base dataset...\n",
      "Generating samples with 2 worker(s)...\n",
      "Collecting global event dataframe...\n",
      "Dev mode enabled: limiting to 1000 patients\n",
      "Collected dataframe with shape: (23830, 38)\n",
      "Generating samples for MortalityPredictionMIMIC4 with 2 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting samples for MortalityPredictionMIMIC4 from 2 workers: 100%|██████████| 100/100 [00:00<00:00, 184.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mortality vocab: {0: 0, 1: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing samples: 100%|██████████| 108/108 [00:00<00:00, 20409.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 108 samples for task MortalityPredictionMIMIC4\n",
      "MIMIC4 demo dataset loaded\n",
      "Number of samples: 108\n",
      "Input features: ['conditions', 'procedures', 'drugs']\n",
      "Output features: ['mortality']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load MIMIC4 demo dataset\n",
    "# Download demo data from: https://physionet.org/files/mimic-iv-demo/2.2/\n",
    "# and place in a local directory, then update ehr_root below\n",
    "ehr_root = \"/home/ubuntu/PyHealth/data/mimic-iv-clinical-database-demo-2.2/\"  # Update this path to your local MIMIC4 demo data\n",
    "\n",
    "dataset = MIMIC4Dataset(\n",
    "    ehr_root=ehr_root,\n",
    "    ehr_tables=[\"diagnoses_icd\", \"procedures_icd\", \"prescriptions\"],\n",
    "    dev=True,\n",
    ")\n",
    "\n",
    "# Set task for time-series modeling\n",
    "task = MortalityPredictionMIMIC4()\n",
    "ts_dataset = dataset.set_task(task, num_workers=2)\n",
    "\n",
    "print(\"MIMIC4 demo dataset loaded\")\n",
    "print(f\"Number of samples: {len(ts_dataset)}\")\n",
    "print(f\"Input features: {list(ts_dataset.input_schema.keys())}\")\n",
    "print(f\"Output features: {list(ts_dataset.output_schema.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train Time-Series VAE\n",
    "\n",
    "The VAE will learn to encode patient trajectories into a latent space and reconstruct them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-series VAE created\n",
      "Input type: timeseries\n",
      "Has embedding model: True\n",
      "Has RNN encoder: True\n",
      "Latent dimension: 64\n"
     ]
    }
   ],
   "source": [
    "# Create time-series VAE model\n",
    "ts_model = VAE(\n",
    "    dataset=ts_dataset,\n",
    "    feature_keys=[\"conditions\"],  # Single sequence feature for VAE\n",
    "    label_key=\"mortality\",\n",
    "    mode=\"binary\",  # Binary classification for mortality prediction\n",
    "    input_type=\"timeseries\",  # Key parameter for time-series mode\n",
    "    hidden_dim=64,  # Latent dimension for medical sequences\n",
    ")\n",
    "\n",
    "print(\"Time-series VAE created\")\n",
    "print(f\"Input type: {ts_model.input_type}\")\n",
    "print(f\"Has embedding model: {hasattr(ts_model, 'embedding_model')}\")\n",
    "print(f\"Has RNN encoder: {hasattr(ts_model, 'encoder_rnn')}\")\n",
    "print(f\"Latent dimension: {ts_model.hidden_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Time-Series VAE Architecture\n",
    "\n",
    "The time-series VAE differs from image VAEs:\n",
    "\n",
    "1. **EmbeddingModel**: Converts categorical sequences to dense vectors\n",
    "2. **RNN Encoder**: Processes sequential embeddings, capturing temporal patterns\n",
    "3. **Latent Space**: Fixed-size representation of the entire sequence\n",
    "4. **Linear Decoder**: Reconstructs the sequence's compressed representation\n",
    "\n",
    "This architecture can learn patterns like \"diabetes → metformin → insulin\" or \"asthma → albuterol → steroids\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (embedding_model): EmbeddingModel(embedding_layers=ModuleDict(\n",
      "    (conditions): Embedding(865, 64, padding_idx=0)\n",
      "    (procedures): Embedding(218, 64, padding_idx=0)\n",
      "    (drugs): Embedding(486, 64, padding_idx=0)\n",
      "  ))\n",
      "  (encoder_rnn): GRU(64, 64, batch_first=True)\n",
      "  (mu): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (log_std2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (decoder_linear): Linear(in_features=64, out_features=64, bias=True)\n",
      ")\n",
      "Metrics: []\n",
      "Device: cuda\n",
      "\n",
      "Training time-series VAE...\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.0001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7cd7dc4a4350>\n",
      "Monitor: loss\n",
      "Monitor criterion: min\n",
      "Epochs: 10\n",
      "Patience: None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 10: 100%|██████████| 4/4 [00:00<00:00, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-4 ---\n",
      "loss: 600.1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 712.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-0, step-4 ---\n",
      "loss: 596.4567\n",
      "New best loss score (596.4567) at epoch-0, step-4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 10: 100%|██████████| 4/4 [00:00<00:00, 290.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-8 ---\n",
      "loss: 570.5898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 731.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-1, step-8 ---\n",
      "loss: 581.0278\n",
      "New best loss score (581.0278) at epoch-1, step-8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 / 10: 100%|██████████| 4/4 [00:00<00:00, 288.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-12 ---\n",
      "loss: 585.5507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 743.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-2, step-12 ---\n",
      "loss: 591.7324\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 / 10: 100%|██████████| 4/4 [00:00<00:00, 291.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-16 ---\n",
      "loss: 571.2698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 740.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-3, step-16 ---\n",
      "loss: 569.4090\n",
      "New best loss score (569.4090) at epoch-3, step-16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 / 10: 100%|██████████| 4/4 [00:00<00:00, 293.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-20 ---\n",
      "loss: 575.8144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 740.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-4, step-20 ---\n",
      "loss: 593.6073\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 / 10: 100%|██████████| 4/4 [00:00<00:00, 293.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-24 ---\n",
      "loss: 554.4583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 730.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-5, step-24 ---\n",
      "loss: 575.9142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 / 10: 100%|██████████| 4/4 [00:00<00:00, 289.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-28 ---\n",
      "loss: 567.8894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 743.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-6, step-28 ---\n",
      "loss: 577.6712\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 / 10: 100%|██████████| 4/4 [00:00<00:00, 294.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-32 ---\n",
      "loss: 590.4861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 737.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-7, step-32 ---\n",
      "loss: 557.5274\n",
      "New best loss score (557.5274) at epoch-7, step-32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 / 10: 100%|██████████| 4/4 [00:00<00:00, 291.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-36 ---\n",
      "loss: 577.2799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 751.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-8, step-36 ---\n",
      "loss: 552.2935\n",
      "New best loss score (552.2935) at epoch-8, step-36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 / 10: 100%|██████████| 4/4 [00:00<00:00, 293.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-40 ---\n",
      "loss: 536.7056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 743.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-9, step-40 ---\n",
      "loss: 547.2967\n",
      "New best loss score (547.2967) at epoch-9, step-40\n",
      "Loaded best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "train_dataloader = get_dataloader(ts_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=ts_model, \n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    metrics=[]  # VAE is unsupervised, no classification metrics needed\n",
    ")\n",
    "\n",
    "# Train the model (reduced epochs for demo)\n",
    "print(\"Training time-series VAE...\")\n",
    "trainer.train(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=train_dataloader,  # Using same data for demo\n",
    "    epochs=10,\n",
    "    monitor=\"loss\",\n",
    "    monitor_criterion=\"min\",\n",
    "    optimizer_params={\"lr\": 1e-4},\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Reconstruction Performance\n",
    "\n",
    "Check how well the VAE reconstructs the original sequences.\n",
    "\n",
    "**What the outputs represent:**\n",
    "- `y_prob`: Reconstructed patient trajectory embeddings (VAE's attempt to recreate the input)\n",
    "- `y_true`: Original RNN hidden states summarizing each patient's diagnosis sequence\n",
    "- `loss`: Reconstruction error measuring how well the VAE captures medical patterns\n",
    "\n",
    "The `y_true` values are 64-dimensional vectors that represent compressed summaries of patient medical histories, capturing temporal patterns like disease progression (e.g., hypertension → diabetes → kidney disease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 715.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "loss: 541.9971\n",
      "\n",
      "Reconstruction shape: torch.Size([32, 64])\n",
      "Original shape: torch.Size([32, 64])\n",
      "Loss: 654.7109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on training data\n",
    "eval_results = trainer.evaluate(train_dataloader)\n",
    "print(\"Evaluation Results:\")\n",
    "for metric, value in eval_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Get reconstruction examples\n",
    "data_batch = next(iter(train_dataloader))\n",
    "with torch.no_grad():\n",
    "    output = ts_model(**data_batch)\n",
    "    \n",
    "print(f\"\\nReconstruction shape: {output['y_prob'].shape}\")\n",
    "print(f\"Original shape: {output['y_true'].shape}\")\n",
    "print(f\"Loss: {output['loss'].item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Medical Sequences\n",
    "\n",
    "Sample from the latent space to generate new patient trajectories and convert them to human-understandable medical codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence representations:\n",
      "Shape: torch.Size([3, 64])\n",
      "Sample values: [ 0.53002435  1.3221712  -0.48090675 -0.45167932 -0.49437132]\n",
      "\n",
      "Converting to medical codes for generated sequence 0:\n",
      "tensor([ 0.0000e+00, -7.3698e-03, -3.6019e+00,  4.2856e+00,  4.9865e+00,\n",
      "        -3.4686e+00, -2.6077e+00,  3.6966e-01,  3.1678e-01,  1.8775e+00,\n",
      "         2.7686e+00,  9.8846e+00,  1.0820e+01,  4.1149e+00,  1.1023e+01,\n",
      "        -4.6142e+00,  6.1783e+00, -1.9797e+00,  3.3450e+00,  4.8513e-01,\n",
      "         4.9730e+00,  4.7466e+00,  6.4790e+00,  4.3559e+00, -4.6351e+00,\n",
      "         5.0865e-01,  2.9454e+00,  4.5632e+00, -6.7101e+00,  1.6942e+00,\n",
      "         9.0058e+00,  1.1524e+00, -4.4482e+00,  3.0030e+00, -6.6758e+00,\n",
      "         1.5273e+01, -9.0026e-01, -5.9171e-01, -8.6225e+00, -6.0907e+00,\n",
      "         3.5220e+00,  9.3690e+00, -5.0509e-01,  1.1058e+01, -2.0280e+00,\n",
      "         9.4648e+00, -1.8569e+00,  1.9413e+00,  6.4853e+00, -8.4831e+00,\n",
      "        -9.4427e-01, -2.8588e+00,  7.2913e-01, -9.2253e+00, -3.6401e+00,\n",
      "         4.1965e+00,  6.1821e+00,  4.8190e-02, -1.0670e+00, -2.3349e+00,\n",
      "        -2.1616e+00,  2.2229e+00,  1.0739e+00,  1.5211e+00,  2.5068e+00,\n",
      "         6.0805e-01, -3.9276e+00, -4.7792e+00,  7.1451e+00,  6.6988e+00,\n",
      "         8.2785e+00, -7.7417e+00,  1.3240e+00, -2.9780e+00,  1.1269e+01,\n",
      "         1.8551e+00, -1.1236e+01, -1.6523e+00, -4.8508e+00,  6.5365e+00,\n",
      "        -1.8226e+00, -2.5214e+00, -1.8810e+00,  7.5196e+00,  3.4994e+00,\n",
      "        -6.2609e-01,  3.3908e+00,  8.6278e+00, -8.5831e+00, -5.9723e+00,\n",
      "        -9.4077e-01, -3.6397e+00, -7.3617e+00,  2.4734e+00,  4.7124e+00,\n",
      "         5.7872e+00,  1.1024e+00, -8.8864e+00,  6.5827e+00,  7.5309e+00,\n",
      "         7.7808e-01, -3.8766e+00,  4.2168e+00, -1.0284e+00, -4.5411e+00,\n",
      "        -1.0719e+00,  3.6934e+00, -5.7031e+00,  4.2286e+00, -2.7739e+00,\n",
      "         5.0000e+00, -1.1350e+00, -1.9651e+00,  1.6179e+00,  7.9560e+00,\n",
      "         4.4798e+00, -1.6526e+00, -1.6522e+00, -3.5508e+00,  3.9089e+00,\n",
      "         2.7357e+00, -3.3986e+00,  6.5241e+00,  1.7675e-01, -5.8271e+00,\n",
      "         9.2375e+00,  2.4214e+00, -3.7925e+00,  1.3557e+00,  1.7812e+00,\n",
      "        -3.0547e-01,  6.5939e-01,  1.0546e+00,  3.9847e+00,  1.8091e+00,\n",
      "        -4.0046e+00, -5.5650e+00,  5.2020e+00,  7.5734e+00, -5.5784e+00,\n",
      "        -1.1468e+01,  8.2059e+00, -7.4497e+00, -6.2369e+00, -7.5726e+00,\n",
      "        -4.4698e+00,  2.5128e+00, -9.4868e+00, -2.7561e+00, -1.1705e+00,\n",
      "         3.3567e+00,  3.7004e+00,  2.6886e+00,  3.2938e-01, -2.1804e+00,\n",
      "         5.4503e+00, -7.9096e-01,  7.1233e+00,  6.3597e+00, -1.5332e+00,\n",
      "         5.3480e-02,  2.1162e-01,  3.2930e+00, -1.8011e+00, -2.7989e+00,\n",
      "         2.7531e+00, -1.1935e+00, -5.0806e+00,  3.6173e+00, -1.6692e+00,\n",
      "        -5.6118e+00, -3.0442e+00,  1.3044e+01,  1.8823e+00,  3.4506e+00,\n",
      "        -8.7729e+00,  4.5545e+00, -3.8803e+00,  1.7737e+00, -2.0081e+00,\n",
      "        -5.4540e+00, -6.3734e+00, -5.1804e-01,  1.9105e+00, -5.7511e+00,\n",
      "        -1.1010e+00,  1.4860e+00,  1.7801e+00,  7.2562e+00,  3.6735e-01,\n",
      "         9.1315e+00,  7.1706e+00, -3.4692e+00,  3.5518e+00, -3.0591e+00,\n",
      "        -1.3145e+00, -6.0018e+00, -5.7727e+00, -3.2378e+00, -5.1966e+00,\n",
      "        -4.1021e+00, -3.1030e+00,  8.1722e+00,  5.2892e+00, -8.7676e+00,\n",
      "         1.9973e+00,  4.6449e+00,  1.3642e+00,  8.9750e-01,  1.6920e-01,\n",
      "         2.3763e+00,  3.4316e-01,  4.2113e+00, -1.6114e-01, -1.8713e+00,\n",
      "        -1.4838e+00,  2.5215e+00,  1.4842e+00,  6.3901e+00,  4.1662e+00,\n",
      "         6.0793e-01,  1.7254e+00,  8.2590e+00,  2.6119e+00, -1.7054e+00,\n",
      "         6.1178e+00, -2.9691e+00, -4.0823e+00,  4.7501e-01,  8.9351e-01,\n",
      "        -1.0580e+00, -1.4648e+00,  2.0005e+00,  4.4008e-01, -1.1741e+01,\n",
      "        -4.2694e-02, -7.7522e-01,  1.9731e+00,  5.9338e+00,  6.1365e+00,\n",
      "        -7.7485e+00,  1.3402e+01,  1.2785e+01, -1.6353e+00, -3.6195e+00,\n",
      "        -1.2166e+00,  3.3741e+00, -1.0241e+01,  6.4584e+00, -1.1245e+00,\n",
      "         5.6069e-01,  4.5313e+00,  7.2805e+00,  5.9941e-01, -4.1223e+00,\n",
      "         2.3223e-01, -6.0213e+00,  1.2135e+00, -4.0671e+00, -3.0445e+00,\n",
      "        -4.7401e+00, -5.2669e+00,  8.4796e+00, -5.4145e+00, -4.7753e+00,\n",
      "        -5.2986e-01, -3.6312e+00,  1.0913e+00, -3.6791e+00,  2.4095e+00,\n",
      "         4.3596e-01, -1.4798e+00, -1.4894e+00,  1.8673e-01,  2.4698e-01,\n",
      "        -2.4453e-01, -3.0582e+00,  2.9348e+00,  2.3117e-01, -2.4103e+00,\n",
      "        -2.8271e+00, -3.9102e+00, -3.6497e+00, -2.4924e+00,  1.9910e+00,\n",
      "        -6.5865e+00, -3.6936e+00, -3.4439e-01, -7.0813e-02,  8.2621e-01,\n",
      "         1.4598e-01, -6.6775e+00,  3.9390e+00, -8.5732e-02,  4.4681e+00,\n",
      "        -5.1826e+00, -6.4087e+00,  2.4561e-01,  1.2722e+00, -2.3493e+00,\n",
      "         2.2532e+00,  3.5215e+00, -1.1521e+00, -5.0680e+00,  1.1928e+01,\n",
      "         2.4243e+00, -4.3520e+00, -8.1776e+00, -1.0246e+00, -6.5926e+00,\n",
      "        -4.7592e+00, -6.3312e-01, -1.0127e+01, -8.8611e-01, -8.8121e+00,\n",
      "         2.8199e-01,  1.7753e+00, -3.0299e+00, -5.9531e+00,  8.6943e-01,\n",
      "         3.5751e+00, -1.1387e+01, -2.3700e+00,  4.8945e+00,  1.6143e+00,\n",
      "         3.5814e+00, -7.8166e+00, -2.4447e+00,  2.9132e+00,  2.6121e+00,\n",
      "         5.3359e+00,  6.1179e+00, -1.4136e+01,  2.7990e-01,  5.0767e+00,\n",
      "         3.2156e+00,  2.9253e+00,  7.9484e+00,  2.6591e+00,  8.8704e+00,\n",
      "         3.1986e+00, -4.0668e-01,  4.6038e+00,  2.6145e+00,  3.5966e+00,\n",
      "         1.0976e+00, -4.4431e+00, -5.4594e+00, -9.8451e-01,  3.2744e+00,\n",
      "         5.2823e+00, -7.2685e+00,  3.1512e+00,  2.7413e-01, -2.7417e+00,\n",
      "         2.4061e+00,  1.0575e+00, -8.0792e+00,  1.5948e+00,  5.0245e-02,\n",
      "        -7.0174e+00, -2.5981e+00,  1.7484e+00,  5.5191e+00,  2.9680e+00,\n",
      "         6.1405e+00, -1.4361e-01,  3.6003e+00,  5.1398e+00, -3.4543e+00,\n",
      "         5.1749e+00, -4.8572e+00, -1.4890e+00,  1.3004e+00,  5.2664e+00,\n",
      "        -3.8776e+00, -2.9888e+00, -7.6976e-01,  3.3617e+00,  8.8238e+00,\n",
      "         5.4425e+00,  6.1032e-01, -2.8261e+00, -4.6408e+00, -2.9985e+00,\n",
      "        -7.4634e+00, -2.6308e+00,  5.1425e-01, -8.0916e-01,  3.9377e+00,\n",
      "        -6.8549e+00, -6.0009e+00, -4.6179e-01,  7.0597e-01, -2.6481e+00,\n",
      "         1.0844e+00,  1.0792e+01, -1.3607e+00,  1.6815e+00, -5.9647e+00,\n",
      "        -3.4795e-01, -5.7725e+00,  8.8240e+00,  1.2161e+01,  1.4274e+00,\n",
      "         5.6612e+00, -2.3413e+00, -1.8727e+00,  4.8331e+00, -1.7449e+00,\n",
      "         9.4813e+00, -4.2424e+00, -4.4759e+00, -3.1925e-01, -1.0234e+00,\n",
      "        -2.3237e-01,  3.3495e+00, -3.8373e-01, -9.8905e-01,  4.4709e+00,\n",
      "         6.2089e-01,  4.7296e+00, -4.6643e-01, -2.9335e+00, -3.2276e-01,\n",
      "        -8.1376e+00, -3.3459e+00, -9.3769e-02, -1.1267e+01, -4.3118e-01,\n",
      "        -3.3150e+00, -6.2661e-01,  4.7186e+00, -3.7383e+00, -6.2295e+00,\n",
      "         5.6783e+00,  1.5134e+00,  3.3611e+00,  3.0486e+00,  1.1139e+00,\n",
      "        -2.3641e+00, -2.5694e+00,  4.0144e+00, -7.9107e-01, -4.3788e-01,\n",
      "         3.9177e+00,  1.1759e+01,  1.4001e+00, -3.9649e-01, -1.1905e+01,\n",
      "        -1.9034e+00, -8.7804e+00,  1.0761e+01,  3.0643e+00,  3.6976e+00,\n",
      "        -2.7494e+00, -2.5087e+00,  9.4577e-01, -2.5091e+00,  5.5027e+00,\n",
      "        -1.1978e+00, -6.2105e+00,  2.2060e+00, -7.4665e+00,  3.0630e+00,\n",
      "        -5.2187e+00, -4.4273e+00, -2.1675e+00,  5.1272e+00,  5.5543e+00,\n",
      "         3.7251e-01,  6.5773e+00, -9.4365e-01, -4.3358e+00, -4.5703e+00,\n",
      "        -5.3149e+00,  1.0750e+01,  4.3271e+00, -1.6464e-01, -9.9271e+00,\n",
      "         4.0325e+00,  5.2930e+00,  4.1603e-01, -9.8539e+00,  9.0224e-02,\n",
      "        -4.6029e+00, -6.9055e-01, -8.8508e-01,  8.0016e-02, -5.1926e+00,\n",
      "        -2.0259e-01,  2.5811e-01,  1.0760e+01, -3.1546e+00, -1.2496e+00,\n",
      "         1.0318e+00, -4.8848e+00, -1.1945e+01,  8.8947e-01, -7.6019e+00,\n",
      "         9.7675e+00,  7.3018e+00,  7.1488e+00,  1.9355e+00, -3.6839e+00,\n",
      "         9.3663e+00, -1.6682e+00, -2.4040e+00, -3.5577e+00, -4.3686e+00,\n",
      "        -2.9042e+00,  7.6098e+00, -2.9299e+00,  5.0070e+00, -1.1131e+00,\n",
      "         2.0663e+00, -1.8503e+00,  2.0247e+00,  2.2851e+00, -4.4661e+00,\n",
      "         3.9783e+00, -1.1042e+00,  6.6821e+00,  1.5496e+00,  7.2286e+00,\n",
      "         7.1757e+00,  1.5642e+00, -3.8730e+00, -6.7046e+00,  4.8879e+00,\n",
      "         6.2288e-01, -1.1968e+00, -6.9655e-01,  9.2160e+00,  8.1812e+00,\n",
      "        -3.2031e+00,  6.3572e+00,  6.4712e+00, -4.6608e+00, -1.7319e+00,\n",
      "        -4.2632e+00, -4.7678e+00,  9.9987e+00,  1.4257e+01,  1.6364e+01,\n",
      "        -1.1067e+01, -1.7239e+00,  5.2205e+00, -5.6597e+00,  4.5558e+00,\n",
      "        -3.2298e+00,  6.6794e+00,  3.8081e+00,  6.7543e+00, -1.6579e+00,\n",
      "        -3.5063e+00, -7.2064e-01, -9.8697e-01,  1.8629e+00, -1.6241e+00,\n",
      "        -3.0487e+00, -3.4707e+00, -3.9215e-01, -4.1220e+00,  1.9885e-01,\n",
      "        -2.1967e+00, -4.9302e-01,  5.2048e+00, -3.4484e+00, -2.8122e+00,\n",
      "        -5.5603e+00, -3.5931e-01,  4.3701e+00, -5.1773e+00, -4.5849e-01,\n",
      "         3.2636e+00,  4.9086e+00,  8.1466e+00,  5.8811e+00,  7.5002e+00,\n",
      "         3.9989e-02,  6.6855e+00,  9.9836e+00, -3.3854e+00,  7.8459e+00,\n",
      "        -1.6212e-01, -5.1125e+00,  5.8930e+00,  8.9414e+00, -1.2838e+00,\n",
      "         9.6739e+00,  1.4556e+00, -4.1944e+00,  6.6870e+00,  6.9083e+00,\n",
      "        -4.6303e+00, -2.2641e+00,  2.0928e+00,  1.6327e+00, -5.0583e+00,\n",
      "         2.3900e+00, -1.3623e+00,  3.1129e+00, -2.0396e+00,  2.0124e+00,\n",
      "        -2.8472e+00,  6.2345e+00,  5.9359e-01, -4.3222e+00, -8.0300e+00,\n",
      "         1.0396e+01,  2.1617e+00,  3.4943e+00,  3.0572e+00, -3.5476e+00,\n",
      "         5.3472e+00,  2.4073e+00,  5.9503e-01,  5.2738e-01, -3.0144e+00,\n",
      "        -5.1299e+00,  2.1250e+00,  1.3509e+00, -2.8952e-01, -6.6030e+00,\n",
      "        -3.6746e+00, -3.7765e+00, -3.2359e+00,  1.3805e+00, -2.2590e+00,\n",
      "        -1.5889e+00,  4.8569e+00,  1.0156e+00,  3.9435e+00, -2.0284e+00,\n",
      "        -1.0859e+01, -2.6059e+00, -6.2794e+00,  8.0509e-01,  2.3528e+00,\n",
      "        -1.6507e+00,  1.1961e+00,  9.9826e+00,  4.8255e+00, -5.6086e+00,\n",
      "        -6.5066e+00, -7.2207e+00,  6.8090e+00,  3.7589e-01, -6.0209e+00,\n",
      "        -8.2463e-01, -7.4694e-01,  8.1887e+00, -2.9548e+00, -1.1866e+00,\n",
      "        -3.5102e+00, -4.6932e+00,  7.2601e+00,  2.2765e+00,  9.4055e+00,\n",
      "         2.7460e+00,  1.4907e+00,  4.7538e-01,  2.9329e+00,  1.2719e+00,\n",
      "        -2.7927e+00, -1.2591e+00, -1.7836e+00,  2.8065e+00,  5.3934e-01,\n",
      "         1.3045e+00,  1.2268e+00, -5.6013e+00,  3.1139e+00,  3.8369e+00,\n",
      "         3.3059e-01,  2.2407e+00,  1.2366e+00, -6.2229e+00, -3.7157e+00,\n",
      "         6.4204e+00,  1.0573e+01, -3.9952e-01,  1.4235e+01, -1.0884e+01,\n",
      "        -2.9518e+00,  1.1950e+00,  1.0031e+00,  2.0499e+00,  1.6345e+00,\n",
      "        -3.8371e+00, -2.6782e+00,  1.9266e+00, -3.5774e+00, -7.1045e+00,\n",
      "        -7.6499e-01, -1.9117e+00, -1.0165e+01, -7.5704e-01, -4.4083e-01,\n",
      "        -2.7491e-01, -1.7376e+00, -7.6327e+00, -4.6055e+00,  5.0006e+00,\n",
      "         5.3006e+00, -2.9642e-01,  6.4890e+00,  8.0494e-01, -7.4606e-01,\n",
      "         5.7291e+00,  1.4712e+00,  1.0860e-01, -7.0036e-01, -2.1391e+00,\n",
      "        -2.0974e+00,  3.6578e+00, -2.5981e+00,  7.4232e+00, -3.8255e+00,\n",
      "         3.1794e+00,  4.3983e-01,  5.2267e+00, -3.5482e+00,  9.6503e+00,\n",
      "         1.6477e-01, -6.9726e+00,  6.3025e+00, -9.1959e+00,  8.4988e+00,\n",
      "        -2.7036e+00,  5.2478e+00,  1.0211e+01, -2.6642e-01,  3.9743e+00,\n",
      "        -1.0607e+01,  1.4849e+01, -4.1829e-01,  3.5922e+00, -1.2574e+00,\n",
      "        -8.8174e-01, -4.4337e-01,  1.6383e+00, -4.3945e+00,  3.5651e-01,\n",
      "        -1.9686e+00,  2.1606e-02,  4.2785e+00, -1.2995e+00,  8.8444e-01,\n",
      "         4.1780e+00, -1.0253e+01, -6.7567e+00, -5.7410e+00,  3.1234e+00,\n",
      "        -4.5726e+00, -1.7247e+00,  9.8022e+00,  5.5747e+00,  4.9975e+00,\n",
      "         3.2196e+00, -3.8409e+00,  4.8316e+00, -6.6928e+00, -4.7451e+00,\n",
      "         1.9149e+00,  2.1189e+00,  7.8778e+00, -3.7329e-02,  1.4081e+00,\n",
      "        -1.3638e+00, -8.6539e+00,  1.6721e-01, -9.8377e+00, -2.7099e+00,\n",
      "        -2.7666e-01, -5.0738e-02, -3.5834e+00,  5.4019e+00, -8.2766e+00,\n",
      "        -3.6412e+00,  3.1811e+00,  1.5183e-01, -9.9372e-01,  3.6720e+00,\n",
      "        -4.4105e-01, -1.4014e+00,  7.7510e+00,  5.7498e+00,  3.5791e+00,\n",
      "        -5.4780e-01, -3.8520e+00, -2.1077e+00,  6.4482e+00,  1.0814e+00,\n",
      "        -7.5035e-01,  4.4298e+00, -8.8133e+00, -2.7812e+00, -5.7001e-01,\n",
      "        -2.6631e+00, -3.3242e+00,  1.3150e+00, -2.7915e+00,  1.7820e+00,\n",
      "         4.7887e-01,  1.1222e+00, -6.1201e+00,  1.3118e+01,  9.0041e+00,\n",
      "         4.9772e+00, -7.0921e+00,  2.8077e-01,  3.6044e+00,  1.8358e+00,\n",
      "        -2.2833e+00, -6.1981e+00,  1.5658e+01,  3.6380e+00,  1.1059e+00,\n",
      "        -1.2764e-01,  6.4083e-01, -1.8858e+00,  2.6034e+00, -3.1585e+00,\n",
      "        -1.9641e+00,  4.2007e+00,  6.5796e-02, -6.1856e-01, -2.3976e+00,\n",
      "        -8.2248e-01,  2.6342e+00,  1.0856e+00,  3.1940e+00, -7.0448e+00,\n",
      "         1.8103e+00,  5.3263e+00,  9.3208e+00,  6.1828e+00,  4.8899e+00,\n",
      "        -3.5434e+00,  3.8317e+00,  8.1334e-01,  1.4348e+00, -5.5027e+00,\n",
      "         5.6279e+00, -1.4003e+01,  1.5963e+00, -3.8147e+00,  3.2877e+00,\n",
      "        -2.3182e+00, -1.9225e+00,  4.8933e+00,  1.3743e+00,  7.1876e+00,\n",
      "         1.7507e+00, -1.3171e+01, -1.0366e+00,  6.4689e+00,  4.3425e+00,\n",
      "         3.5808e+00, -5.5930e+00, -3.2690e-01,  5.2676e+00,  2.4258e+00],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "topk() got multiple values for argument 'k'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m top_k = \u001b[32m3\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(similarities)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m top_similarities, top_indices = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtopk\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilarities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[32m5\u001b[39m, seq_embeds.shape[\u001b[32m0\u001b[39m])):  \u001b[38;5;66;03m# Show first 5 positions\u001b[39;00m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPosition \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpos\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: topk() got multiple values for argument 'k'"
     ]
    }
   ],
   "source": [
    "# Generate new sequences by sampling from latent space\n",
    "ts_model.eval()\n",
    "with torch.no_grad():\n",
    "    # Sample random latent vectors\n",
    "    latent_samples = torch.randn(3, ts_model.hidden_dim).to(ts_model.device)\n",
    "    \n",
    "    # Decode to get sequence representations\n",
    "    generated_sequences = ts_model.decoder(latent_samples)\n",
    "    \n",
    "    print(\"Generated sequence representations:\")\n",
    "    print(f\"Shape: {generated_sequences.shape}\")\n",
    "    print(f\"Sample values: {generated_sequences[0, :5].cpu().numpy()}\")\n",
    "    \n",
    "    # Convert embeddings to human-understandable medical codes\n",
    "    # Find closest codes in embedding space\n",
    "    \n",
    "    # Get all code embeddings from the embedding model\n",
    "    conditions_vocab = list(ts_dataset.input_processors['conditions'].code_vocab.keys())\n",
    "    all_codes = conditions_vocab  # Use conditions vocabulary\n",
    "    code_embeddings = ts_model.embedding_model.embedding_layers['conditions'].weight.data  # [vocab_size, embed_dim]\n",
    "    \n",
    "    print(f\"\\nConverting to medical codes for generated sequence 0:\")\n",
    "    \n",
    "    # The generated sequence is a single embedding vector, not a sequence\n",
    "    seq_embed = generated_sequences[0]  # [embed_dim]\n",
    "    \n",
    "    # Compute cosine similarity with all code embeddings\n",
    "    similarities = torch.matmul(seq_embed, code_embeddings.t())  # [vocab_size]\n",
    "    \n",
    "    # Get top 3 most similar codes\n",
    "    top_k = 3\n",
    "    top_similarities, top_indices = torch.topk(similarities, top_k, dim=0)\n",
    "    \n",
    "    codes = [all_codes[idx] for idx in top_indices.cpu().numpy()]\n",
    "    sims = top_similarities.cpu().numpy()\n",
    "    print(f\"Top {top_k} similar medical codes: {codes}\")\n",
    "    print(f\"Similarities: {sims}\")\n",
    "    \n",
    "    print(\"\\nNote: These represent the most likely medical codes for the generated sequence.\")\n",
    "    print(\"In practice, you might use beam search or other decoding strategies for better results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "### How Time-Series VAE Works:\n",
    "1. **Input Processing**: Categorical sequences (diagnoses, procedures) are embedded using the EmbeddingModel\n",
    "2. **Sequence Encoding**: RNN processes the embedded sequence to capture temporal patterns\n",
    "3. **Latent Compression**: Variable-length sequences become fixed-size latent vectors\n",
    "4. **Reconstruction**: Decoder attempts to recreate the embedded sequence representation\n",
    "5. **Code Generation**: Generated embeddings are mapped back to medical codes using nearest neighbor search\n",
    "\n",
    "### Medical Applications:\n",
    "- **Trajectory Analysis**: Understand typical patient progression patterns from real MIMIC4 data\n",
    "- **Synthetic Data**: Generate realistic patient histories for research and model training\n",
    "- **Anomaly Detection**: Identify unusual treatment sequences in clinical practice\n",
    "- **Outcome Prediction**: Learn sequence patterns that correlate with mortality and other outcomes\n",
    "- **Data Augmentation**: Create additional training samples for underrepresented conditions\n",
    "\n",
    "### Key Improvements in This Version:\n",
    "- **Real Data**: Uses MIMIC4 demo dataset instead of synthetic data for more realistic modeling\n",
    "- **Multiple Sequences**: Models both diagnoses and procedures simultaneously\n",
    "- **Human-Readable Output**: Converts generated embeddings back to interpretable medical codes\n",
    "- **Clinical Relevance**: Focuses on in-hospital mortality prediction task\n",
    "\n",
    "### Differences from Image VAE:\n",
    "- **Temporal vs Spatial**: Captures time-ordered dependencies instead of spatial patterns\n",
    "- **Variable Length**: Handles sequences of different lengths\n",
    "- **Categorical Data**: Works with medical codes, diagnoses, treatments\n",
    "- **Generation**: Creates new realistic patient trajectories with interpretable medical codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDocstring:\u001b[39m\n",
      "topk(input, k, dim=None, largest=True, sorted=True, *, out=None) -> (Tensor, LongTensor)\n",
      "\n",
      "Returns the :attr:`k` largest elements of the given :attr:`input` tensor along\n",
      "a given dimension.\n",
      "\n",
      "If :attr:`dim` is not given, the last dimension of the `input` is chosen.\n",
      "\n",
      "If :attr:`largest` is ``False`` then the `k` smallest elements are returned.\n",
      "\n",
      "A namedtuple of `(values, indices)` is returned with the `values` and\n",
      "`indices` of the largest `k` elements of each row of the `input` tensor in the\n",
      "given dimension `dim`.\n",
      "\n",
      "The boolean option :attr:`sorted` if ``True``, will make sure that the returned\n",
      "`k` elements are themselves sorted\n",
      "\n",
      ".. note::\n",
      "    When using `torch.topk`, the indices of tied elements are not guaranteed to be stable\n",
      "    and may vary across different invocations.\n",
      "\n",
      "Args:\n",
      "    input (Tensor): the input tensor.\n",
      "    k (int): the k in \"top-k\"\n",
      "    dim (int, optional): the dimension to sort along\n",
      "    largest (bool, optional): controls whether to return largest or\n",
      "           smallest elements\n",
      "    sorted (bool, optional): controls whether to return the elements\n",
      "           in sorted order\n",
      "\n",
      "Keyword args:\n",
      "    out (tuple, optional): the output tuple of (Tensor, LongTensor) that can be\n",
      "        optionally given to be used as output buffers\n",
      "\n",
      "Example::\n",
      "\n",
      "    >>> x = torch.arange(1., 6.)\n",
      "    >>> x\n",
      "    tensor([ 1.,  2.,  3.,  4.,  5.])\n",
      "    >>> torch.topk(x, 3)\n",
      "    torch.return_types.topk(values=tensor([5., 4., 3.]), indices=tensor([4, 3, 2]))\n",
      "\u001b[31mType:\u001b[39m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    " torch.topk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
