{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Modeling with VAE\n",
    "\n",
    "This notebook demonstrates how to use the enhanced VAE model for time-series data analysis and generation. Unlike image VAEs that work with spatial patterns, time-series VAEs model sequential patterns in medical data.\n",
    "\n",
    "## Key Concepts:\n",
    "- **Sequence Encoding**: RNN-based encoder captures temporal dependencies\n",
    "- **Latent Representation**: Compressed representation of patient trajectories\n",
    "- **Sequence Generation**: RNN decoder reconstructs realistic medical sequences\n",
    "\n",
    "## Applications:\n",
    "- Patient trajectory modeling and generation\n",
    "- Medical sequence anomaly detection\n",
    "- Synthetic data generation for rare conditions\n",
    "- Treatment pattern analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import split_by_visit, get_dataloader\n",
    "from pyhealth.trainer import Trainer\n",
    "from pyhealth.models import VAE\n",
    "from pyhealth.datasets import SampleDataset\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Time-Series Medical Data\n",
    "\n",
    "We'll create sample patient trajectories showing disease progression and treatment sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 100%|██████████| 4/4 [00:00<00:00, 19949.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-series dataset created\n",
      "Number of samples: 4\n",
      "Vocabulary size: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create sample time-series medical data\n",
    "ts_samples = [\n",
    "    {\n",
    "        \"patient_id\": \"patient-0\",\n",
    "        \"visit_id\": \"visit-0\",\n",
    "        \"visits\": [\"diabetes\", \"metformin\", \"hba1c_test\", \"insulin\"],\n",
    "        \"label\": 1.0,\n",
    "    },\n",
    "    {\n",
    "        \"patient_id\": \"patient-1\",\n",
    "        \"visit_id\": \"visit-1\",\n",
    "        \"visits\": [\"hypertension\", \"lisinopril\", \"bp_check\", \"followup\"],\n",
    "        \"label\": 0.5,\n",
    "    },\n",
    "    {\n",
    "        \"patient_id\": \"patient-2\",\n",
    "        \"visit_id\": \"visit-2\",\n",
    "        \"visits\": [\"asthma\", \"albuterol\", \"peak_flow\", \"steroids\"],\n",
    "        \"label\": 0.8,\n",
    "    },\n",
    "    {\n",
    "        \"patient_id\": \"patient-3\",\n",
    "        \"visit_id\": \"visit-3\",\n",
    "        \"visits\": [\"depression\", \"sertraline\", \"therapy\", \"counseling\"],\n",
    "        \"label\": 0.3,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create dataset\n",
    "ts_dataset = SampleDataset(\n",
    "    samples=ts_samples,\n",
    "    input_schema={\"visits\": \"sequence\"},\n",
    "    output_schema={\"label\": \"regression\"},\n",
    "    dataset_name=\"timeseries_demo\",\n",
    ")\n",
    "\n",
    "print(\"Time-series dataset created\")\n",
    "print(f\"Number of samples: {len(ts_dataset)}\")\n",
    "print(f\"Vocabulary size: {len(ts_dataset.input_processors['visits'].code_vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train Time-Series VAE\n",
    "\n",
    "The VAE will learn to encode patient trajectories into a latent space and reconstruct them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-series VAE created\n",
      "Input type: timeseries\n",
      "Has embedding model: True\n",
      "Has RNN encoder: True\n",
      "Latent dimension: 32\n"
     ]
    }
   ],
   "source": [
    "# Create time-series VAE model\n",
    "ts_model = VAE(\n",
    "    dataset=ts_dataset,\n",
    "    feature_keys=[\"visits\"],\n",
    "    label_key=\"label\",\n",
    "    mode=\"regression\",\n",
    "    input_type=\"timeseries\",  # Key parameter for time-series mode\n",
    "    hidden_dim=32,  # Smaller latent dimension for sequences\n",
    ")\n",
    "\n",
    "print(\"Time-series VAE created\")\n",
    "print(f\"Input type: {ts_model.input_type}\")\n",
    "print(f\"Has embedding model: {hasattr(ts_model, 'embedding_model')}\")\n",
    "print(f\"Has RNN encoder: {hasattr(ts_model, 'encoder_rnn')}\")\n",
    "print(f\"Latent dimension: {ts_model.hidden_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Time-Series VAE Architecture\n",
    "\n",
    "The time-series VAE differs from image VAEs:\n",
    "\n",
    "1. **EmbeddingModel**: Converts categorical sequences to dense vectors\n",
    "2. **RNN Encoder**: Processes sequential embeddings, capturing temporal patterns\n",
    "3. **Latent Space**: Fixed-size representation of the entire sequence\n",
    "4. **Linear Decoder**: Reconstructs the sequence's compressed representation\n",
    "\n",
    "This architecture can learn patterns like \"diabetes → metformin → insulin\" or \"asthma → albuterol → steroids\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (embedding_model): EmbeddingModel(embedding_layers=ModuleDict(\n",
      "    (visits): Embedding(18, 32, padding_idx=0)\n",
      "  ))\n",
      "  (encoder_rnn): GRU(32, 32, batch_first=True)\n",
      "  (mu): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (log_std2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (decoder_linear): Linear(in_features=32, out_features=32, bias=True)\n",
      ")\n",
      "Metrics: ['kl_divergence', 'mse', 'mae']\n",
      "Device: cuda\n",
      "\n",
      "Training time-series VAE...\n",
      "Training:\n",
      "Batch size: 1\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7a19402482c0>\n",
      "Monitor: kl_divergence\n",
      "Monitor criterion: min\n",
      "Epochs: 5\n",
      "Patience: None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 5: 100%|██████████| 4/4 [00:00<00:00, 249.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-4 ---\n",
      "loss: 12.0682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 632.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-0, step-4 ---\n",
      "kl_divergence: 6.1801\n",
      "mse: 0.0002\n",
      "mae: 0.0102\n",
      "loss: 13.0345\n",
      "New best kl_divergence score (6.1801) at epoch-0, step-4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 5: 100%|██████████| 4/4 [00:00<00:00, 266.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-8 ---\n",
      "loss: 14.3934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 590.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-1, step-8 ---\n",
      "kl_divergence: 5.3789\n",
      "mse: 0.0002\n",
      "mae: 0.0103\n",
      "loss: 11.8951\n",
      "New best kl_divergence score (5.3789) at epoch-1, step-8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 / 5: 100%|██████████| 4/4 [00:00<00:00, 253.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-12 ---\n",
      "loss: 12.0990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 710.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-2, step-12 ---\n",
      "kl_divergence: 7.1621\n",
      "mse: 0.0003\n",
      "mae: 0.0113\n",
      "loss: 13.0983\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 / 5: 100%|██████████| 4/4 [00:00<00:00, 277.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-16 ---\n",
      "loss: 11.9011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 614.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-3, step-16 ---\n",
      "kl_divergence: 7.2321\n",
      "mse: 0.0003\n",
      "mae: 0.0119\n",
      "loss: 13.5714\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 / 5: 100%|██████████| 4/4 [00:00<00:00, 264.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-20 ---\n",
      "loss: 15.0954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 602.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-4, step-20 ---\n",
      "kl_divergence: 6.8994\n",
      "mse: 0.0003\n",
      "mae: 0.0119\n",
      "loss: 10.0336\n",
      "Loaded best model\n",
      "Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "train_dataloader = get_dataloader(ts_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=ts_model, \n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    metrics=[\"kl_divergence\", \"mse\", \"mae\"]\n",
    ")\n",
    "\n",
    "# Train the model (reduced epochs for demo)\n",
    "print(\"Training time-series VAE...\")\n",
    "trainer.train(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=train_dataloader,  # Using same data for demo\n",
    "    epochs=5,\n",
    "    monitor=\"kl_divergence\",\n",
    "    monitor_criterion=\"min\",\n",
    "    optimizer_params={\"lr\": 1e-3},\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Reconstruction Performance\n",
    "\n",
    "Check how well the VAE reconstructs the original sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 4/4 [00:00<00:00, 599.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "kl_divergence: 8.0949\n",
      "mse: 0.0003\n",
      "mae: 0.0125\n",
      "loss: 13.2461\n",
      "\n",
      "Reconstruction shape: torch.Size([1, 32])\n",
      "Original shape: torch.Size([1, 32])\n",
      "Loss: 23.6351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on training data\n",
    "eval_results = trainer.evaluate(train_dataloader)\n",
    "print(\"Evaluation Results:\")\n",
    "for metric, value in eval_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Get reconstruction examples\n",
    "data_batch = next(iter(train_dataloader))\n",
    "with torch.no_grad():\n",
    "    output = ts_model(**data_batch)\n",
    "    \n",
    "print(f\"\\nReconstruction shape: {output['y_prob'].shape}\")\n",
    "print(f\"Original shape: {output['y_true'].shape}\")\n",
    "print(f\"Loss: {output['loss'].item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Medical Sequences\n",
    "\n",
    "Sample from the latent space to generate new patient trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence representations:\n",
      "Shape: torch.Size([3, 32])\n",
      "Sample values: [-1.181458   -0.8360508   0.49716952 -0.88951784  0.26240543]\n"
     ]
    }
   ],
   "source": [
    "# Generate new sequences by sampling from latent space\n",
    "ts_model.eval()\n",
    "with torch.no_grad():\n",
    "    # Sample random latent vectors\n",
    "    latent_samples = torch.randn(3, ts_model.hidden_dim).to(ts_model.device)\n",
    "    \n",
    "    # Decode to get sequence representations\n",
    "    generated_sequences = ts_model.decoder(latent_samples)\n",
    "    \n",
    "    print(\"Generated sequence representations:\")\n",
    "    print(f\"Shape: {generated_sequences.shape}\")\n",
    "    print(f\"Sample values: {generated_sequences[0, :5].cpu().numpy()}\")\n",
    "    \n",
    "    # The generated sequences represent points in the embedded space\n",
    "    # In a full implementation, you might use a decoder RNN to generate\n",
    "    # actual token sequences, but here we show the latent generation concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "### How Time-Series VAE Works:\n",
    "1. **Input Processing**: Categorical sequences are embedded using the EmbeddingModel\n",
    "2. **Sequence Encoding**: RNN processes the embedded sequence to capture temporal patterns\n",
    "3. **Latent Compression**: Variable-length sequences become fixed-size latent vectors\n",
    "4. **Reconstruction**: Decoder attempts to recreate the embedded sequence representation\n",
    "\n",
    "### Medical Applications:\n",
    "- **Trajectory Analysis**: Understand typical patient progression patterns\n",
    "- **Synthetic Data**: Generate realistic patient histories for research\n",
    "- **Anomaly Detection**: Identify unusual treatment sequences\n",
    "- **Outcome Prediction**: Learn sequence patterns that correlate with outcomes\n",
    "\n",
    "### Differences from Image VAE:\n",
    "- **Temporal vs Spatial**: Captures time-ordered dependencies instead of spatial patterns\n",
    "- **Variable Length**: Handles sequences of different lengths\n",
    "- **Categorical Data**: Works with medical codes, diagnoses, treatments\n",
    "- **Generation**: Creates new realistic patient trajectories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
